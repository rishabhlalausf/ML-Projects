{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Text Mining - Classification - SCIKIT-LEARN\n",
    "\n",
    "We will predict the category of a product based on the description of the product.\n",
    "\n",
    "**The unit of analysis is a product**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>HP 680 Original Ink Advantage Cartridge (Black...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>Bold N Elegant Navy Blue Thin Summer Pregnancy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Books</td>\n",
       "      <td>The Travel Book: A Journey Through Every Count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Electronics</td>\n",
       "      <td>Tiny Deal Compact 10x25 Mini Binoculars Telesc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clothing &amp; Accessories</td>\n",
       "      <td>Nimble House 16Pcs/Set Unisex Women Men No Tie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Category                                        Description\n",
       "0             Electronics  HP 680 Original Ink Advantage Cartridge (Black...\n",
       "1  Clothing & Accessories  Bold N Elegant Navy Blue Thin Summer Pregnancy...\n",
       "2                   Books  The Travel Book: A Journey Through Every Count...\n",
       "3             Electronics  Tiny Deal Compact 10x25 Mini Binoculars Telesc...\n",
       "4  Clothing & Accessories  Nimble House 16Pcs/Set Unisex Women Men No Tie..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign the \"target\" variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = products['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign the \"text\" (input) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = products[['Description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set, train_y, test_y = train_test_split(input_data, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3500, 1), (3500,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 1), (1500,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn: Text preparation\n",
    "\n",
    "Create a pipeline to transform the text column and create a term by document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col(df):\n",
    "    #Create a copy so that we don't overwrite the existing dataframe\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    # First, conver the dataframe column to a numpy array. Then, call the ravel function to make it one-dimensional\n",
    "    return np.array(df).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Dehman 100-Percent Silky Satin Hair Beauty Pillowcase, Black, King Size DEHMANSATIN Silk originated in INDIA and it is an honor to present this ancient oriental gift to you. The collective wisdom of the sericulture people of this land has been condensed DEHMAN has always adhered to its original heart from generation to generation. From raw satin silk material collection to processing and to finished products,each step is carefully selected. DEHMAN hopes that every customer will have a wonderful satin silk experience and enjoy the silky noble life. Why Choose DEHMAN Pillowcase ? Material：DEHMAN Satin Silk pillowcase is crafted by 19 momme pure mulberry silk. Both sides of the pillowcase is organic and natural satin silk.Light weight and easy to carry. Design: It is designed with hidden zipper closure.With Queen(20x30inches) and King(20x36inches) and Standard size(20x26inches) in various kinds colours. Quality：Superior durable plain color ,not easy to run after washing.Exquisite craftmanship of the neat stitches. Benefits:DEHMAN pillowcase is the most natural anti-aging product, hypoallergenic,smooth,soft,breathable. Prevent hair from becoming knotted and matted,have good sleeping,reduce facial wrinkles.It takes you into a beautiful dream.Enjoy the sweet sleep and comfortable daily！ SATIN SILK INSTRUCTION:  Dry cleaning or washing by hand are the best methods for cleaning silk for longer use time.Machine wash accepted, please useOur pillowcases are hypoallergenic and made from the finest 100 percent pure charmeuse satin silk. Compared to cotton pillowcases, silk dries out skin and hair comparably less and are recommended by dermatologists to minimize wrinkles. Our satin silk is smooth and dissipates static electricity which makes it a perfect material for combating morning bed hair and frizziness. Can be hand washed but also durable enough to withstand repeated machine washing on delicate settings. Air drying is recommended as excessive heat can damage satin silk.',\n",
       "       'MCQs in Pediatric Dentistry ',\n",
       "       'A History of Ancient and Early Medieval India: From the Stone Age to the 12th Century About the Author Upinder Singh is Professor in the Department of History at the University of Delhi. She taught history at St. Stephen¿s College, Delhi, from 1981 until 2004, after which she joined the faculty of the Department of History at the University of Delhi. Professor Singh¿s wide range of research interests and expertise include the analysis of ancient and early medieval inscriptions; social and economic history; religious institutions and patronage; history of archaeology; and modern history of ancient monuments. Her research papers have been published in various national and international journals. Her published books include: Kings, Brahmanas, and Temples in Orissa: An Epigraphic Study (AD 300¿1147) (1994); Ancient Delhi (1999; 2nd edn., 2006); a book for children, Mysteries of the Past: Archaeological Sites in India (2002); The Discovery of Ancient India: Early Archaeologists and the Beginnings of Archaeology (2004); and Delhi: Ancient History (edited, 2006).',\n",
       "       ...,\n",
       "       'Amazon Brand - Solimo Ultra-Soft 100% Cotton 2 Piece Bath Towel (Midnight Blue and Tangy Red) Color Name:Midnight Blue and Tangy Red   The 100% cotton Solimo premium Smart Twist 2 piece bath towel set includes 2 extra soft and highly absorbent bath towels of size 140x70 cm. These towels are made from a unique yarn twisting process which is created by wrapping soft bundle of cotton fibers with very fine low twist cotton yarn. This helps increase absorbency and fluffiness of the towels. These bath towels can be machine or hand washed.',\n",
       "       'JoJo Designs Polyester Cushion Fillers 16x16-inches (White) - Set of 5 Set of 5 pieces of fluffy micro fiber cushion fillers in 16x16 inches. These fillers features are they will remain in shape, They are very comfortable and give full support to your head, they are extra fluffy and durable, They are washable and hygienic to your skin.',\n",
       "       \"Indus Route by Pantaloons Men's Kurta Rust colored self designed kurta, featuring full sleeves, mandarin collar and regular fit pattern. Made from superior quality fabric for maximum comfort.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_col(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_column = ['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_svd_components = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transformer = Pipeline(steps=[\n",
    "                ('my_new_column', FunctionTransformer(new_col)),\n",
    "                ('text', TfidfVectorizer(stop_words='english')),\n",
    "                ('svd', TruncatedSVD(n_components=number_svd_components, n_iter=10))\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "                     ('text', text_transformer, text_column),\n",
    "                    ],\n",
    "        remainder='drop')\n",
    "\n",
    "#passtrough is an optional step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.32127476e-01, -3.83815352e-02, -5.52127985e-02, ...,\n",
       "         2.19671309e-02, -1.95717275e-02, -1.90545645e-02],\n",
       "       [ 1.19672838e-03,  1.09071177e-03, -9.41521625e-06, ...,\n",
       "        -3.07134638e-03,  8.67785154e-03,  6.44866776e-03],\n",
       "       [ 5.74701078e-02,  5.16487292e-02,  8.81057288e-03, ...,\n",
       "         1.61169437e-02, -7.52522684e-03, -1.14667795e-03],\n",
       "       ...,\n",
       "       [ 1.59120292e-01, -7.66943792e-02, -1.60781830e-01, ...,\n",
       "        -2.52529891e-03, -1.63111933e-02,  8.17335898e-03],\n",
       "       [ 8.31440381e-02, -4.33959857e-02, -3.44149656e-02, ...,\n",
       "        -7.17453246e-03, -6.18195590e-03, -3.02089228e-02],\n",
       "       [ 9.66538621e-02, -3.95970843e-02, -1.19857668e-01, ...,\n",
       "         4.28482353e-02, -2.47389018e-02, -1.78786143e-02]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_set)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0197115 ,  0.0121762 ,  0.00564652, ...,  0.01736046,\n",
       "         0.02325228, -0.00598611],\n",
       "       [ 0.08027585, -0.04060881,  0.02606995, ...,  0.01262605,\n",
       "         0.04518485,  0.02717815],\n",
       "       [ 0.17327444, -0.07025064, -0.0460695 , ...,  0.00624072,\n",
       "        -0.00765925, -0.01024442],\n",
       "       ...,\n",
       "       [ 0.08834409,  0.03663293,  0.00627167, ..., -0.00516674,\n",
       "        -0.00452773, -0.01228504],\n",
       "       [ 0.08826245, -0.03472008,  0.03563941, ...,  0.01446637,\n",
       "         0.01764299, -0.01875452],\n",
       "       [ 0.01982621, -0.00944311,  0.02909595, ..., -0.01503946,\n",
       "        -0.00123765,  0.01915129]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_set)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 500)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.38142857142857145\n"
     ]
    }
   ],
   "source": [
    "#Baseline Train Accuracy\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_y, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.386\n"
     ]
    }
   ],
   "source": [
    "#Baseline Test Accuracy\n",
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_y, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try one of the classifiers we have covered so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=16, n_jobs=-1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=16, n_jobs=-1) \n",
    "\n",
    "rnd_clf.fit(train_x, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8848571428571429\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = rnd_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.87\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = rnd_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[325,   5,   3,  32],\n",
       "       [  1, 214,   2,  41],\n",
       "       [ 10,   0, 204,  84],\n",
       "       [ 12,   3,   2, 562]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Usually created on test set\n",
    "confusion_matrix(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try another classifier we have covered so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(max_iter=100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9574285714285714\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = sgd_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.9426666666666667\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = sgd_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Books', 'Household', 'Household', ..., 'Books', 'Household',\n",
       "       'Electronics'], dtype='<U22')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[336,   6,   4,  19],\n",
       "       [  1, 253,   1,   3],\n",
       "       [  8,   1, 274,  15],\n",
       "       [ 12,   7,   9, 551]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Usually created on test set\n",
    "confusion_matrix(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for the number of components\n",
    "\n",
    "**Determine whether increasing/decreasing the number of components increases/decreases the two models' accuracies** Discussing of the findings below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is run with two different component values:\n",
    "\n",
    "The test accuracy \n",
    "Baseline = 0.386\n",
    "\n",
    "Components are set at = 300\n",
    "Random Forest Classifer Model is 0.8993\n",
    "The SGDClassifier model is 0.9366666666666666  \n",
    " \n",
    "\n",
    "Comparison: with components = 500\n",
    "Baseline = 0.386 (unchanged)\n",
    "Random Forest Classifier = 0.87 (reduced) \n",
    "SGD Classifier = 0.942 (increased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
