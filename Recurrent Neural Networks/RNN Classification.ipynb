{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - RNN Classification\n",
    "\n",
    "In this notebook, we will perform a classification task using RNNs (i.e., a sequence to value prediction). We have hourly power consumption of households for 12 hours. Based on this, we will determine whether the power grid is strained (1) or not (0). \n",
    "\n",
    "Therefore, use the columns from `Hour 0` to `Hour 11` to predict the `target` column in the `power.csv` data set.\n",
    "\n",
    "\n",
    "Hint2: Don't forget to adjust the number of neurons in the input layers correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rishabh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rishabh\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour 0</th>\n",
       "      <th>Hour 1</th>\n",
       "      <th>Hour 2</th>\n",
       "      <th>Hour 3</th>\n",
       "      <th>Hour 4</th>\n",
       "      <th>Hour 5</th>\n",
       "      <th>Hour 6</th>\n",
       "      <th>Hour 7</th>\n",
       "      <th>Hour 8</th>\n",
       "      <th>Hour 9</th>\n",
       "      <th>Hour 10</th>\n",
       "      <th>Hour 11</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.550633</td>\n",
       "      <td>2.523400</td>\n",
       "      <td>2.582333</td>\n",
       "      <td>2.541667</td>\n",
       "      <td>2.475733</td>\n",
       "      <td>2.476233</td>\n",
       "      <td>2.455800</td>\n",
       "      <td>2.447200</td>\n",
       "      <td>2.441733</td>\n",
       "      <td>3.146133</td>\n",
       "      <td>2.661733</td>\n",
       "      <td>2.576000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.596933</td>\n",
       "      <td>1.619567</td>\n",
       "      <td>2.473733</td>\n",
       "      <td>2.731133</td>\n",
       "      <td>2.431133</td>\n",
       "      <td>2.479667</td>\n",
       "      <td>1.690200</td>\n",
       "      <td>1.332133</td>\n",
       "      <td>1.375167</td>\n",
       "      <td>1.050900</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>2.651900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.534933</td>\n",
       "      <td>0.540467</td>\n",
       "      <td>0.575367</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>0.565333</td>\n",
       "      <td>1.426467</td>\n",
       "      <td>0.602067</td>\n",
       "      <td>0.547433</td>\n",
       "      <td>0.525067</td>\n",
       "      <td>1.270300</td>\n",
       "      <td>0.393767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.085867</td>\n",
       "      <td>0.651233</td>\n",
       "      <td>0.634600</td>\n",
       "      <td>0.653000</td>\n",
       "      <td>0.646067</td>\n",
       "      <td>0.628400</td>\n",
       "      <td>0.611067</td>\n",
       "      <td>0.612533</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.606067</td>\n",
       "      <td>1.471867</td>\n",
       "      <td>0.834533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.456000</td>\n",
       "      <td>0.286300</td>\n",
       "      <td>0.310833</td>\n",
       "      <td>0.250933</td>\n",
       "      <td>0.277667</td>\n",
       "      <td>0.308633</td>\n",
       "      <td>0.610400</td>\n",
       "      <td>1.563533</td>\n",
       "      <td>1.421867</td>\n",
       "      <td>3.324400</td>\n",
       "      <td>3.207567</td>\n",
       "      <td>1.425433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hour 0    Hour 1    Hour 2    Hour 3    Hour 4    Hour 5    Hour 6  \\\n",
       "0  2.550633  2.523400  2.582333  2.541667  2.475733  2.476233  2.455800   \n",
       "1  1.596933  1.619567  2.473733  2.731133  2.431133  2.479667  1.690200   \n",
       "2  0.534933  0.540467  0.575367  0.526500  0.521900  0.565333  1.426467   \n",
       "3  1.085867  0.651233  0.634600  0.653000  0.646067  0.628400  0.611067   \n",
       "4  0.456000  0.286300  0.310833  0.250933  0.277667  0.308633  0.610400   \n",
       "\n",
       "     Hour 7    Hour 8    Hour 9   Hour 10   Hour 11  target  \n",
       "0  2.447200  2.441733  3.146133  2.661733  2.576000       1  \n",
       "1  1.332133  1.375167  1.050900  0.585900  2.651900       1  \n",
       "2  0.602067  0.547433  0.525067  1.270300  0.393767       0  \n",
       "3  0.612533  0.660100  0.606067  1.471867  0.834533       0  \n",
       "4  1.563533  1.421867  3.324400  3.207567  1.425433       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power = pd.read_csv('power.csv')\n",
    "\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1417, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 1000 days are for train\n",
    "train = power.iloc[:1000]\n",
    "\n",
    "# Remaining 417 days are for test\n",
    "test = power.iloc[-417:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Input and Target values\n",
    "\n",
    "The first 12 columns (hourly data) will be input to predict the last column (i.e., target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 12 columns (from 0 to 11) are inputs\n",
    "\n",
    "train_inputs = train.iloc[:,:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add one more dimension to make it ready for RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an additional dimension for train\n",
    "\n",
    "train_x = np.array(train_inputs).reshape(1000,12,1)\n",
    "\n",
    "train_x.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last column is TARGET\n",
    "\n",
    "train_target = train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 12 columns are inputs\n",
    "\n",
    "test_inputs = test.iloc[:,:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 12, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create an additional dimension for test\n",
    "\n",
    "test_x = np.array(test_inputs).reshape(417,12,1)\n",
    "\n",
    "test_x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last column is TARGET\n",
    "\n",
    "test_target = test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000    0\n",
       "1001    1\n",
       "1002    0\n",
       "1003    0\n",
       "1004    0\n",
       "       ..\n",
       "1412    0\n",
       "1413    1\n",
       "1414    0\n",
       "1415    0\n",
       "1416    0\n",
       "Name: target, Length: 417, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a normal (cross-sectional) NN\n",
    "\n",
    "This model assumes that the data is NOT a time-series data set. It treats the data as cross-sectional and the columns being independent of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[12, 1]),\n",
    "    keras.layers.Dense(12, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 32s 519ms/step - loss: 0.8548 - accuracy: 0.4770 - val_loss: 0.6837 - val_accuracy: 0.5588\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 11s 352ms/step - loss: 0.6440 - accuracy: 0.6470 - val_loss: 0.6193 - val_accuracy: 0.6906\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 11s 357ms/step - loss: 0.5728 - accuracy: 0.7260 - val_loss: 0.5724 - val_accuracy: 0.7074\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 10s 334ms/step - loss: 0.5356 - accuracy: 0.7400 - val_loss: 0.5494 - val_accuracy: 0.7074\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 10s 327ms/step - loss: 0.4981 - accuracy: 0.7500 - val_loss: 0.5359 - val_accuracy: 0.7074\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.4822 - accuracy: 0.7450 - val_loss: 0.5218 - val_accuracy: 0.7002\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.4789 - accuracy: 0.7510 - val_loss: 0.5369 - val_accuracy: 0.7194\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 11s 350ms/step - loss: 0.4646 - accuracy: 0.7550 - val_loss: 0.5109 - val_accuracy: 0.7170\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 11s 356ms/step - loss: 0.4656 - accuracy: 0.7400 - val_loss: 0.5119 - val_accuracy: 0.7242\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 10s 310ms/step - loss: 0.4555 - accuracy: 0.7540 - val_loss: 0.5145 - val_accuracy: 0.7122\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 11s 345ms/step - loss: 0.4573 - accuracy: 0.7640 - val_loss: 0.5276 - val_accuracy: 0.7098\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 10s 318ms/step - loss: 0.4543 - accuracy: 0.7570 - val_loss: 0.5139 - val_accuracy: 0.7170\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 10s 319ms/step - loss: 0.4486 - accuracy: 0.7640 - val_loss: 0.5236 - val_accuracy: 0.7074\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 10s 331ms/step - loss: 0.4502 - accuracy: 0.7710 - val_loss: 0.5162 - val_accuracy: 0.7314\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 11s 344ms/step - loss: 0.4486 - accuracy: 0.7620 - val_loss: 0.5442 - val_accuracy: 0.7146\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 10s 335ms/step - loss: 0.4550 - accuracy: 0.7600 - val_loss: 0.5142 - val_accuracy: 0.7266\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 10s 314ms/step - loss: 0.4398 - accuracy: 0.7720 - val_loss: 0.5273 - val_accuracy: 0.7386\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.4478 - accuracy: 0.7730 - val_loss: 0.5147 - val_accuracy: 0.7218\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 0.4433 - accuracy: 0.7710 - val_loss: 0.5117 - val_accuracy: 0.7290\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 10s 311ms/step - loss: 0.4520 - accuracy: 0.7720 - val_loss: 0.5150 - val_accuracy: 0.7290\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 11s 346ms/step - loss: 0.4403 - accuracy: 0.7760 - val_loss: 0.5142 - val_accuracy: 0.7266\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 11s 349ms/step - loss: 0.4424 - accuracy: 0.7620 - val_loss: 0.5163 - val_accuracy: 0.7314\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 10s 317ms/step - loss: 0.4358 - accuracy: 0.7710 - val_loss: 0.5401 - val_accuracy: 0.7074\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 11s 350ms/step - loss: 0.4422 - accuracy: 0.7800 - val_loss: 0.5225 - val_accuracy: 0.7218\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 9s 306ms/step - loss: 0.4387 - accuracy: 0.7700 - val_loss: 0.5120 - val_accuracy: 0.7218\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 10s 337ms/step - loss: 0.4382 - accuracy: 0.7670 - val_loss: 0.5297 - val_accuracy: 0.7194\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 12s 394ms/step - loss: 0.4331 - accuracy: 0.7820 - val_loss: 0.5192 - val_accuracy: 0.7410\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 11s 347ms/step - loss: 0.4328 - accuracy: 0.7860 - val_loss: 0.5338 - val_accuracy: 0.7194\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.4326 - accuracy: 0.7790 - val_loss: 0.5148 - val_accuracy: 0.7314\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 10s 333ms/step - loss: 0.4276 - accuracy: 0.7890 - val_loss: 0.5242 - val_accuracy: 0.7146\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 11s 352ms/step - loss: 0.4253 - accuracy: 0.7800 - val_loss: 0.5312 - val_accuracy: 0.7482\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 0.4313 - accuracy: 0.7820 - val_loss: 0.5187 - val_accuracy: 0.7170\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 11s 344ms/step - loss: 0.4211 - accuracy: 0.7760 - val_loss: 0.5179 - val_accuracy: 0.7338\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 11s 358ms/step - loss: 0.4212 - accuracy: 0.7880 - val_loss: 0.5352 - val_accuracy: 0.7098\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 0.4252 - accuracy: 0.7820 - val_loss: 0.5251 - val_accuracy: 0.7314\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 10s 318ms/step - loss: 0.4144 - accuracy: 0.7900 - val_loss: 0.5210 - val_accuracy: 0.7098\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 0.4186 - accuracy: 0.7920 - val_loss: 0.5293 - val_accuracy: 0.7458\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 10s 320ms/step - loss: 0.4198 - accuracy: 0.7910 - val_loss: 0.5235 - val_accuracy: 0.7218\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 10s 330ms/step - loss: 0.4170 - accuracy: 0.7940 - val_loss: 0.5316 - val_accuracy: 0.7218\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 0.4261 - accuracy: 0.7890 - val_loss: 0.5253 - val_accuracy: 0.7482\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 11s 350ms/step - loss: 0.4080 - accuracy: 0.8000 - val_loss: 0.5333 - val_accuracy: 0.7098\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 10s 317ms/step - loss: 0.4142 - accuracy: 0.7880 - val_loss: 0.5305 - val_accuracy: 0.7506\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 11s 351ms/step - loss: 0.4165 - accuracy: 0.7870 - val_loss: 0.5313 - val_accuracy: 0.7482\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 12s 388ms/step - loss: 0.4134 - accuracy: 0.8020 - val_loss: 0.5368 - val_accuracy: 0.7266\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 12s 383ms/step - loss: 0.4071 - accuracy: 0.8010 - val_loss: 0.5264 - val_accuracy: 0.7458\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 12s 384ms/step - loss: 0.4044 - accuracy: 0.8070 - val_loss: 0.5483 - val_accuracy: 0.7242\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 11s 344ms/step - loss: 0.4059 - accuracy: 0.8000 - val_loss: 0.5340 - val_accuracy: 0.7218\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 10s 335ms/step - loss: 0.4031 - accuracy: 0.8020 - val_loss: 0.5544 - val_accuracy: 0.7338\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 0.4224 - accuracy: 0.7980 - val_loss: 0.5486 - val_accuracy: 0.7482\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 10s 336ms/step - loss: 0.4046 - accuracy: 0.8030 - val_loss: 0.5452 - val_accuracy: 0.7506\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=50,\n",
    "                    validation_data=(test_x, test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5451728105545044, 0.7505995035171509]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.55\n",
      "accuracy: 75.06%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple RNN with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.SimpleRNN(32, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 18s 265ms/step - loss: 0.5614 - accuracy: 0.7000 - val_loss: 0.5472 - val_accuracy: 0.7050\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 7s 216ms/step - loss: 0.4834 - accuracy: 0.7520 - val_loss: 0.6775 - val_accuracy: 0.6859\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 3s 108ms/step - loss: 0.4843 - accuracy: 0.7380 - val_loss: 0.6132 - val_accuracy: 0.6835\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 4s 125ms/step - loss: 0.5514 - accuracy: 0.7190 - val_loss: 0.5243 - val_accuracy: 0.7098\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 3s 110ms/step - loss: 0.4917 - accuracy: 0.7550 - val_loss: 0.5660 - val_accuracy: 0.6954\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 3s 104ms/step - loss: 0.5255 - accuracy: 0.7410 - val_loss: 0.5456 - val_accuracy: 0.7482\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.4942 - accuracy: 0.7460 - val_loss: 0.5223 - val_accuracy: 0.7146\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 0.4709 - accuracy: 0.7650 - val_loss: 0.5115 - val_accuracy: 0.7362\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 3s 110ms/step - loss: 0.4728 - accuracy: 0.7560 - val_loss: 0.5301 - val_accuracy: 0.7386\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.4730 - accuracy: 0.7640 - val_loss: 0.4979 - val_accuracy: 0.7266\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 0.4559 - accuracy: 0.7590 - val_loss: 0.5101 - val_accuracy: 0.7386\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 3s 95ms/step - loss: 0.4689 - accuracy: 0.7560 - val_loss: 0.4987 - val_accuracy: 0.7554\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.4522 - accuracy: 0.7730 - val_loss: 0.5259 - val_accuracy: 0.7146\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 0.4586 - accuracy: 0.7700 - val_loss: 0.4894 - val_accuracy: 0.7554\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.4484 - accuracy: 0.7730 - val_loss: 0.4830 - val_accuracy: 0.7482\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 5s 147ms/step - loss: 0.4372 - accuracy: 0.7790 - val_loss: 0.5131 - val_accuracy: 0.7362\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 4s 127ms/step - loss: 0.4479 - accuracy: 0.7720 - val_loss: 0.5804 - val_accuracy: 0.7170\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 4s 120ms/step - loss: 0.4653 - accuracy: 0.7500 - val_loss: 0.5332 - val_accuracy: 0.7290\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 3s 113ms/step - loss: 0.4429 - accuracy: 0.7850 - val_loss: 0.5280 - val_accuracy: 0.7314\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 0.4542 - accuracy: 0.7850 - val_loss: 0.5629 - val_accuracy: 0.7242\n",
      "Epoch 20: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=50,\n",
    "                    validation_data=(test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5628818273544312, 0.7242206335067749]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.56\n",
      "accuracy: 72.42%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 8s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions are probabilities.\n",
    "\n",
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rounding the probabilities determines 1 or 0\n",
    "\n",
    "np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120,  90],\n",
       "       [ 25, 182]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_target, np.round(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple RNN with two or more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True, input_shape=[n_steps, n_inputs] ),\n",
    "    keras.layers.SimpleRNN(32, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(32), \n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 21s 301ms/step - loss: 0.6208 - accuracy: 0.6600 - val_loss: 0.6256 - val_accuracy: 0.6954\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 0.5443 - accuracy: 0.7280 - val_loss: 0.6465 - val_accuracy: 0.6978\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 0.5177 - accuracy: 0.7420 - val_loss: 0.6237 - val_accuracy: 0.6715\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 0.5805 - accuracy: 0.6900 - val_loss: 0.5329 - val_accuracy: 0.7074\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 4s 124ms/step - loss: 0.5006 - accuracy: 0.7530 - val_loss: 0.5718 - val_accuracy: 0.7002\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.5147 - accuracy: 0.7430 - val_loss: 0.5123 - val_accuracy: 0.7026\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 5s 174ms/step - loss: 0.5134 - accuracy: 0.7320 - val_loss: 0.4960 - val_accuracy: 0.7578\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 4s 128ms/step - loss: 0.4785 - accuracy: 0.7520 - val_loss: 0.5114 - val_accuracy: 0.7482\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 0.4894 - accuracy: 0.7490 - val_loss: 0.5860 - val_accuracy: 0.6978\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 4s 125ms/step - loss: 0.4836 - accuracy: 0.7550 - val_loss: 0.4947 - val_accuracy: 0.7506\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 7s 238ms/step - loss: 0.4650 - accuracy: 0.7740 - val_loss: 0.5105 - val_accuracy: 0.7170\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 0.4766 - accuracy: 0.7610 - val_loss: 0.5010 - val_accuracy: 0.7458\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 5s 165ms/step - loss: 0.4539 - accuracy: 0.7730 - val_loss: 0.5436 - val_accuracy: 0.7050\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 6s 178ms/step - loss: 0.4659 - accuracy: 0.7710 - val_loss: 0.5081 - val_accuracy: 0.7482\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 6s 204ms/step - loss: 0.4626 - accuracy: 0.7630 - val_loss: 0.5157 - val_accuracy: 0.7410\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5238609910011292, 0.7458033561706543]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.56\n",
      "accuracy: 72.42%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(12, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 26s 316ms/step - loss: 0.5913 - accuracy: 0.6810 - val_loss: 0.5722 - val_accuracy: 0.6906\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 7s 241ms/step - loss: 0.4974 - accuracy: 0.7500 - val_loss: 0.5151 - val_accuracy: 0.7434\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.4758 - accuracy: 0.7540 - val_loss: 0.5370 - val_accuracy: 0.7458\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 4s 142ms/step - loss: 0.4909 - accuracy: 0.7540 - val_loss: 0.5187 - val_accuracy: 0.7146\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 4s 129ms/step - loss: 0.4721 - accuracy: 0.7540 - val_loss: 0.5095 - val_accuracy: 0.7242\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.4751 - accuracy: 0.7500 - val_loss: 0.5081 - val_accuracy: 0.7410\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 0.4667 - accuracy: 0.7530 - val_loss: 0.5276 - val_accuracy: 0.7530\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 0.4635 - accuracy: 0.7660 - val_loss: 0.5071 - val_accuracy: 0.7314\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.4682 - accuracy: 0.7560 - val_loss: 0.5102 - val_accuracy: 0.7314\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 0.4578 - accuracy: 0.7670 - val_loss: 0.5094 - val_accuracy: 0.7530\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.4622 - accuracy: 0.7620 - val_loss: 0.5171 - val_accuracy: 0.7122\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 4s 134ms/step - loss: 0.4592 - accuracy: 0.7570 - val_loss: 0.5075 - val_accuracy: 0.7362\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.4563 - accuracy: 0.7620 - val_loss: 0.5151 - val_accuracy: 0.7170\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5150845050811768, 0.7170263528823853]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.52\n",
      "accuracy: 71.70%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM with two or more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(12, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(12, return_sequences=True),\n",
    "    keras.layers.LSTM(12),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 32s 378ms/step - loss: 0.6447 - accuracy: 0.6300 - val_loss: 0.5863 - val_accuracy: 0.7074\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 8s 257ms/step - loss: 0.5475 - accuracy: 0.7220 - val_loss: 0.5439 - val_accuracy: 0.7122\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 0.5233 - accuracy: 0.7410 - val_loss: 0.5383 - val_accuracy: 0.7338\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.5153 - accuracy: 0.7420 - val_loss: 0.5243 - val_accuracy: 0.7434\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 5s 164ms/step - loss: 0.4861 - accuracy: 0.7540 - val_loss: 0.5718 - val_accuracy: 0.7026\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 0.5259 - accuracy: 0.7400 - val_loss: 0.5582 - val_accuracy: 0.7026\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 0.4959 - accuracy: 0.7380 - val_loss: 0.5089 - val_accuracy: 0.7602\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 5s 149ms/step - loss: 0.4672 - accuracy: 0.7530 - val_loss: 0.4989 - val_accuracy: 0.7338\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.4626 - accuracy: 0.7520 - val_loss: 0.5110 - val_accuracy: 0.7602\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 12s 370ms/step - loss: 0.4525 - accuracy: 0.7560 - val_loss: 0.4965 - val_accuracy: 0.7410\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 0.4481 - accuracy: 0.7690 - val_loss: 0.5164 - val_accuracy: 0.7170\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 5s 176ms/step - loss: 0.4466 - accuracy: 0.7620 - val_loss: 0.4978 - val_accuracy: 0.7674\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 5s 167ms/step - loss: 0.4410 - accuracy: 0.7740 - val_loss: 0.5117 - val_accuracy: 0.7290\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 5s 175ms/step - loss: 0.4448 - accuracy: 0.7730 - val_loss: 0.5069 - val_accuracy: 0.7194\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 5s 171ms/step - loss: 0.4408 - accuracy: 0.7800 - val_loss: 0.5076 - val_accuracy: 0.7242\n",
      "Epoch 15: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5076159834861755, 0.7242206335067749]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.51\n",
      "accuracy: 72.42%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(12, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 24s 334ms/step - loss: 0.6680 - accuracy: 0.6090 - val_loss: 0.5965 - val_accuracy: 0.7050\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 7s 241ms/step - loss: 0.5057 - accuracy: 0.7480 - val_loss: 0.5394 - val_accuracy: 0.7074\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 4s 137ms/step - loss: 0.4844 - accuracy: 0.7490 - val_loss: 0.5238 - val_accuracy: 0.7602\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 0.4893 - accuracy: 0.7580 - val_loss: 0.5092 - val_accuracy: 0.7218\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 0.4684 - accuracy: 0.7550 - val_loss: 0.5128 - val_accuracy: 0.7194\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 0.4790 - accuracy: 0.7470 - val_loss: 0.5056 - val_accuracy: 0.7314\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 0.4690 - accuracy: 0.7530 - val_loss: 0.5255 - val_accuracy: 0.7578\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 5s 150ms/step - loss: 0.4592 - accuracy: 0.7610 - val_loss: 0.5037 - val_accuracy: 0.7266\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 0.4604 - accuracy: 0.7510 - val_loss: 0.5038 - val_accuracy: 0.7386\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 4s 131ms/step - loss: 0.4521 - accuracy: 0.7680 - val_loss: 0.5037 - val_accuracy: 0.7626\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.4565 - accuracy: 0.7680 - val_loss: 0.5168 - val_accuracy: 0.7242\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 4s 127ms/step - loss: 0.4516 - accuracy: 0.7620 - val_loss: 0.5059 - val_accuracy: 0.7482\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 4s 129ms/step - loss: 0.4501 - accuracy: 0.7740 - val_loss: 0.5186 - val_accuracy: 0.7242\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 0.4550 - accuracy: 0.7770 - val_loss: 0.4999 - val_accuracy: 0.7650\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.4465 - accuracy: 0.7790 - val_loss: 0.5201 - val_accuracy: 0.7242\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 4s 119ms/step - loss: 0.4459 - accuracy: 0.7820 - val_loss: 0.4990 - val_accuracy: 0.7506\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 4s 126ms/step - loss: 0.4405 - accuracy: 0.7770 - val_loss: 0.5356 - val_accuracy: 0.7506\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 4s 127ms/step - loss: 0.4491 - accuracy: 0.7750 - val_loss: 0.4971 - val_accuracy: 0.7530\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 4s 132ms/step - loss: 0.4456 - accuracy: 0.7770 - val_loss: 0.5029 - val_accuracy: 0.7506\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 4s 128ms/step - loss: 0.4585 - accuracy: 0.7640 - val_loss: 0.5002 - val_accuracy: 0.7506\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5002162456512451, 0.7505995035171509]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.50\n",
      "accuracy: 75.06%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU with two or more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 12\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(32, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(32, return_sequences=True),\n",
    "    keras.layers.GRU(32),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 31s 331ms/step - loss: 0.6080 - accuracy: 0.6800 - val_loss: 0.5458 - val_accuracy: 0.7146\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 0.4960 - accuracy: 0.7440 - val_loss: 0.5113 - val_accuracy: 0.7362\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 0.4782 - accuracy: 0.7450 - val_loss: 0.5425 - val_accuracy: 0.7530\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 7s 219ms/step - loss: 0.5267 - accuracy: 0.7350 - val_loss: 0.5152 - val_accuracy: 0.7626\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 9s 289ms/step - loss: 0.4654 - accuracy: 0.7590 - val_loss: 0.5322 - val_accuracy: 0.7170\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 0.4955 - accuracy: 0.7450 - val_loss: 0.5055 - val_accuracy: 0.7194\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 0.4643 - accuracy: 0.7570 - val_loss: 0.4968 - val_accuracy: 0.7410\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 0.4526 - accuracy: 0.7630 - val_loss: 0.4941 - val_accuracy: 0.7530\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 0.4608 - accuracy: 0.7710 - val_loss: 0.4948 - val_accuracy: 0.7650\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 0.4507 - accuracy: 0.7720 - val_loss: 0.5095 - val_accuracy: 0.7338\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 0.4471 - accuracy: 0.7660 - val_loss: 0.5069 - val_accuracy: 0.7650\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 5s 146ms/step - loss: 0.4580 - accuracy: 0.7670 - val_loss: 0.5064 - val_accuracy: 0.7746\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 5s 153ms/step - loss: 0.4434 - accuracy: 0.7620 - val_loss: 0.5316 - val_accuracy: 0.7194\n",
      "Epoch 13: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_target, epochs=20,\n",
    "                   validation_data = (test_x, test_target), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5316129326820374, 0.7194244861602783]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_target, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.53\n",
      "accuracy: 71.94%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
